{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"imdb_master.csv\", encoding=\"latin-1\") # The Sentiment140 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# from os import listdir\n",
    "\n",
    "# neutral_ = []\n",
    "\n",
    "# neutral = listdir(\"neutral\") # the directory with neutral data\n",
    "# for file in neutral:\n",
    "#     with open(\"neutral/\"+file, \"r\", encoding=\"utf-8\") as f:\n",
    "#         for line in f:\n",
    "#             neutral_.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = data[data[\"label\"] == \"pos\"]\n",
    "neg = data[data[\"label\"] == \"neg\"]\n",
    "\n",
    "pos_text, neg_text = pos[\"review\"].tolist(), neg[\"review\"].tolist()\n",
    "\n",
    "pos_text = pos_text[:2000]\n",
    "neg_text = neg_text[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import TweetTokenizer\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "def word_features(tweet):\n",
    "    features = tknzr.tokenize(tweet)\n",
    "    return dict([(word), True] for word in features)\n",
    "\n",
    "# tweets = data.iloc[:,5]\n",
    "\n",
    "neg_tweets = [(word_features(tweet), \"neg\") for tweet in neg_text]\n",
    "pos_tweets = [(word_features(tweet), \"pos\") for tweet in pos_text]\n",
    "# neu_tweets = [(word_features(tweet), \"neu\") for tweet in neutral_]\n",
    "# taking only 20000 tweets, plus ~3500 neutral sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_set = neg_tweets + pos_tweets\n",
    "import random\n",
    "\n",
    "random.seed(123456)\n",
    "random.shuffle(prep_set)\n",
    "\n",
    "train = prep_set[:3500]\n",
    "test = prep_set[3500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "import nltk.classify.util\n",
    "classifier = NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.882\n",
      "Most Informative Features\n",
      "                   waste = True              neg : pos    =     27.8 : 1.0\n",
      "                   Avoid = True              neg : pos    =     23.7 : 1.0\n",
      "                   Radio = True              pos : neg    =     22.3 : 1.0\n",
      "                  Sci-Fi = True              neg : pos    =     21.7 : 1.0\n",
      "                  turkey = True              neg : pos    =     20.4 : 1.0\n",
      "               franchise = True              neg : pos    =     19.7 : 1.0\n",
      "                    Hong = True              pos : neg    =     19.6 : 1.0\n",
      "           extraordinary = True              pos : neg    =     19.6 : 1.0\n",
      "                 zombies = True              neg : pos    =     19.0 : 1.0\n",
      "                    7/10 = True              pos : neg    =     19.0 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, test))\n",
    "classifier.show_most_informative_features()\n",
    "classifier.classify(word_features(\"\"\"You are a bad person.\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is C2F6-13A6\n",
      "\n",
      " Directory of C:\\Users\\user\n",
      "\n",
      "02/16/2020  02:19 PM    <DIR>          .\n",
      "02/16/2020  02:19 PM    <DIR>          ..\n",
      "12/01/2019  01:43 PM    <DIR>          .anaconda\n",
      "12/08/2019  01:32 PM    <DIR>          .conda\n",
      "12/08/2019  01:28 PM                43 .condarc\n",
      "06/25/2019  11:42 AM    <DIR>          .idlerc\n",
      "02/16/2020  01:33 PM    <DIR>          .ipynb_checkpoints\n",
      "06/25/2019  12:29 PM    <DIR>          .ipython\n",
      "12/01/2019  01:45 PM    <DIR>          .jupyter\n",
      "06/25/2019  12:30 PM    <DIR>          .keras\n",
      "12/08/2019  01:16 PM    <DIR>          .matplotlib\n",
      "07/03/2019  06:22 PM    <DIR>          .PyCharmCE2019.1\n",
      "07/24/2019  04:52 PM    <DIR>          .pylint.d\n",
      "12/27/2019  05:20 PM                54 .python_history\n",
      "06/25/2019  06:04 PM    <DIR>          .spyder-py3\n",
      "12/14/2019  06:40 PM    <DIR>          .vscode\n",
      "02/14/2020  05:42 PM    <DIR>          3D Objects\n",
      "12/27/2019  09:13 PM            95,750 A Star graph.jpeg\n",
      "06/26/2011  06:53 AM    <DIR>          aclImdb\n",
      "12/30/2019  07:57 PM        84,125,825 aclImdb_v1.tar.gz\n",
      "02/11/2020  07:12 PM    <DIR>          Anaconda3\n",
      "02/14/2020  05:42 PM    <DIR>          Contacts\n",
      "12/08/2019  12:30 PM    <DIR>          Desktop\n",
      "10/19/2019  08:42 AM    <DIR>          Documents\n",
      "02/16/2020  01:17 PM    <DIR>          Downloads\n",
      "02/14/2020  05:42 PM    <DIR>          Favorites\n",
      "12/02/2019  11:28 AM    <DIR>          github.com\n",
      "02/11/2020  07:05 AM       135,469,499 imdb_master.csv\n",
      "12/24/2019  06:20 PM           113,863 LabNo.1_SACHIN_BYANJU_CS.ipynb\n",
      "12/29/2019  06:47 PM            46,831 LabNo.2_SACHIN _BYANJU_CS.ipynb\n",
      "12/29/2019  06:44 PM            20,000 LabNo.3_SACHIN_BYANJU_CS.ipynb\n",
      "12/31/2019  07:57 AM            52,603 LabNo.4_SACHIN_BYANJU_CS.ipynb\n",
      "02/08/2020  10:17 PM           196,875 LabNo.5_SACHIN_BYANJU_CS.ipynb\n",
      "02/09/2020  09:48 PM           255,697 LabNo.6_SACHIN_BYANJU_CS.ipynb\n",
      "02/11/2020  08:23 AM             5,012 LabNo.7_SACHIN_BYANJU_CS.ipynb\n",
      "02/14/2020  07:10 AM           231,221 LabNo.8_SACHIN_BYANJU_CS.ipynb\n",
      "02/14/2020  05:42 PM    <DIR>          Links\n",
      "02/16/2020  02:15 PM            91,801 movie_review.ipynb\n",
      "02/14/2020  05:42 PM    <DIR>          Music\n",
      "02/08/2020  07:53 AM           546,511 Naive Bayes Self .ipynb\n",
      "02/16/2020  02:18 PM         9,303,551 NB.pickle\n",
      "02/13/2020  07:47 AM    <DIR>          OneDrive\n",
      "02/14/2020  05:42 PM    <DIR>          Saved Games\n",
      "12/29/2019  06:40 PM    <DIR>          scikit_learn_data\n",
      "02/14/2020  05:42 PM    <DIR>          Searches\n",
      "02/16/2020  01:37 PM            11,134 SHARAD.ipynb\n",
      "07/22/2019  08:40 AM    <DIR>          source\n",
      "02/08/2020  07:42 AM            85,201 train.txt\n",
      "02/16/2020  02:19 PM             7,857 Train_NB_unigram.ipynb\n",
      "02/14/2020  05:42 PM    <DIR>          Videos\n",
      "12/02/2019  04:23 PM             6,537 web_traffic.tsv\n",
      "              20 File(s)    230,665,865 bytes\n",
      "              31 Dir(s)  154,627,420,160 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"NB.pickle\", \"wb\") as f:\n",
    "    pickle.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
